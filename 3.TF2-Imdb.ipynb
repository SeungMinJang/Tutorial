{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "25000 train sequences\n",
      "25000 test sequences\n",
      "Pad sequences (samples x time)\n",
      "x_train shape: (25000, 80)\n",
      "x_test shape: (25000, 80)\n",
      "Build model...\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, None, 128)         2560000   \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 128)               131584    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 2,691,713\n",
      "Trainable params: 2,691,713\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/smsm8898/miniconda3/envs/tf/lib/python3.7/site-packages/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25000 samples, validate on 25000 samples\n",
      "Epoch 1/15\n",
      "25000/25000 [==============================] - 99s 4ms/step - loss: 0.4566 - accuracy: 0.7827 - val_loss: 0.4247 - val_accuracy: 0.8062\n",
      "Epoch 2/15\n",
      "25000/25000 [==============================] - 100s 4ms/step - loss: 0.3028 - accuracy: 0.8749 - val_loss: 0.3817 - val_accuracy: 0.8339\n",
      "Epoch 3/15\n",
      "25000/25000 [==============================] - 99s 4ms/step - loss: 0.2174 - accuracy: 0.9153 - val_loss: 0.4180 - val_accuracy: 0.8293\n",
      "Epoch 4/15\n",
      "25000/25000 [==============================] - 100s 4ms/step - loss: 0.1550 - accuracy: 0.9417 - val_loss: 0.4815 - val_accuracy: 0.8207\n",
      "Epoch 5/15\n",
      "25000/25000 [==============================] - 98s 4ms/step - loss: 0.1162 - accuracy: 0.9568 - val_loss: 0.5550 - val_accuracy: 0.8245\n",
      "Epoch 6/15\n",
      "25000/25000 [==============================] - 102s 4ms/step - loss: 0.0830 - accuracy: 0.9708 - val_loss: 0.6354 - val_accuracy: 0.8184\n",
      "Epoch 7/15\n",
      "25000/25000 [==============================] - 99s 4ms/step - loss: 0.0636 - accuracy: 0.9775 - val_loss: 0.7054 - val_accuracy: 0.8113\n",
      "Epoch 8/15\n",
      "25000/25000 [==============================] - 98s 4ms/step - loss: 0.0452 - accuracy: 0.9852 - val_loss: 0.7302 - val_accuracy: 0.8074\n",
      "Epoch 9/15\n",
      "25000/25000 [==============================] - 99s 4ms/step - loss: 0.0329 - accuracy: 0.9892 - val_loss: 0.8908 - val_accuracy: 0.8149\n",
      "Epoch 10/15\n",
      "25000/25000 [==============================] - 99s 4ms/step - loss: 0.0280 - accuracy: 0.9911 - val_loss: 0.8663 - val_accuracy: 0.8109\n",
      "Epoch 11/15\n",
      "25000/25000 [==============================] - 99s 4ms/step - loss: 0.0214 - accuracy: 0.9930 - val_loss: 0.9461 - val_accuracy: 0.7980\n",
      "Epoch 12/15\n",
      "25000/25000 [==============================] - 100s 4ms/step - loss: 0.0233 - accuracy: 0.9928 - val_loss: 1.0540 - val_accuracy: 0.8110\n",
      "Epoch 13/15\n",
      "25000/25000 [==============================] - 99s 4ms/step - loss: 0.0135 - accuracy: 0.9956 - val_loss: 1.1150 - val_accuracy: 0.8083\n",
      "Epoch 14/15\n",
      "25000/25000 [==============================] - 100s 4ms/step - loss: 0.0141 - accuracy: 0.9955 - val_loss: 1.1211 - val_accuracy: 0.8074\n",
      "Epoch 15/15\n",
      "25000/25000 [==============================] - 99s 4ms/step - loss: 0.0128 - accuracy: 0.9958 - val_loss: 1.1812 - val_accuracy: 0.8089\n",
      "25000/25000 [==============================] - 10s 388us/step\n",
      "Test score: 1.1811842606273293\n",
      "Test accuracy: 0.8088799715042114\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding\n",
    "from keras.layers import LSTM\n",
    "from keras.datasets import imdb\n",
    "\n",
    "max_features = 20000\n",
    "# cut texts after this number of words (among top max_features most common words)\n",
    "maxlen = 80\n",
    "batch_size = 32\n",
    "\n",
    "print('Loading data...')\n",
    "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features)\n",
    "print(len(x_train), 'train sequences')\n",
    "print(len(x_test), 'test sequences')\n",
    "\n",
    "print('Pad sequences (samples x time)')\n",
    "x_train = sequence.pad_sequences(x_train, maxlen=maxlen)\n",
    "x_test = sequence.pad_sequences(x_test, maxlen=maxlen)\n",
    "print('x_train shape:', x_train.shape)\n",
    "print('x_test shape:', x_test.shape)\n",
    "\n",
    "print('Build model...')\n",
    "model = Sequential([\n",
    "    Embedding(max_features, 128),\n",
    "    LSTM(128, dropout=0.2, recurrent_dropout=0.2),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# try using different optimizers and different optimizer configs\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "print('Train...')\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=15,\n",
    "          validation_data=(x_test, y_test))\n",
    "score, acc = model.evaluate(x_test, y_test,\n",
    "                            batch_size=batch_size)\n",
    "print('Test score:', score)\n",
    "print('Test accuracy:', acc)\n",
    "\n",
    "model.save('./models/imdb_classification.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "[TF]",
   "language": "python",
   "name": "tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
